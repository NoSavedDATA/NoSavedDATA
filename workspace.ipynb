{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2dc78d7-a5f5-4ad8-a01c-68912ad5aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, glob, os\n",
    "\n",
    "for file in glob.glob('a/*'):\n",
    "    shutil.copy(file, f'b/{file.split(os.sep)[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf15e4c3-6015-41d0-b314-1dca5148c5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], device='cuda:0'),\n",
       " tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]], device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nosaveddata import *\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "a=torch.arange(2,device='cuda').long()[:,None].repeat_interleave(15,0)\n",
    "\n",
    "a,torch.zeros(6,1,device='cuda').long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ac57f6d-e45c-43c9-a29f-e94d81fc69b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0002, 0.0058])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "p1 = 0.6697\n",
    "p2 = 0.6649\n",
    "n = 10000\n",
    "\n",
    "def statistical_difference(p1, p2, n):\n",
    "    \n",
    "    d=torch.tensor(p1-p2).abs()\n",
    "\n",
    "    std = 1.65 * math.sqrt((p1*(1-p1) + p2*(1-p2))/n)\n",
    "    \n",
    "    difference = torch.tensor([d-std, d+std])\n",
    "    \n",
    "    return difference.sort()[0]\n",
    "\n",
    "print(statistical_difference(0.834, 0.831, 100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a8e20d0-e2d2-4ce7-9c42-12aea4125e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPALA ResNet Parameters: 1.56M\n",
      "IMPALA ResNet Parameters: 1.63M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 128, 12, 9]), torch.Size([32, 128, 12, 9]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nosaveddata import *\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class IMPALA_Resnet(nn.Module):\n",
    "    def __init__(self, first_channels=12, scale_width=1, norm=True, init=init_relu, act=nn.SiLU()):\n",
    "        super().__init__()\n",
    "        self.norm=norm\n",
    "        self.init=init\n",
    "        self.act =act\n",
    "        \n",
    "        self.cnn = nn.Sequential(self.get_block(first_channels, 16*scale_width),\n",
    "                                 self.get_block(16*scale_width, 32*scale_width),\n",
    "                                 self.get_block(32*scale_width, 32*scale_width, last_relu=True))\n",
    "        params_count(self, 'IMPALA ResNet')\n",
    "    def get_block(self, in_hiddens, out_hiddens, last_relu=False):\n",
    "        \n",
    "        blocks = nn.Sequential(DQN_Conv(in_hiddens, out_hiddens, 3, 1, 1, max_pool=True, act=self.act, norm=self.norm, init=self.init),\n",
    "                               Residual_Block(out_hiddens, out_hiddens, norm=self.norm, act=self.act, init=self.init),\n",
    "                               Residual_Block(out_hiddens, out_hiddens, norm=self.norm, act=self.act, init=self.init, out_act=self.act if last_relu else nn.Identity())\n",
    "                              )\n",
    "        \n",
    "        return blocks\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.cnn(X)\n",
    "\n",
    "\n",
    "class IMPALA_YY(nn.Module):\n",
    "    def __init__(self, first_channels=12, scale_width=1, norm=True, init=init_relu, act=nn.SiLU()):\n",
    "        super().__init__()\n",
    "        self.norm=norm\n",
    "        self.init=init\n",
    "        self.act =act\n",
    "\n",
    "        self.yin = self.get_yin(first_channels, 16*scale_width, 32*scale_width)\n",
    "        \n",
    "        self.yang = self.get_yang(first_channels, 16*scale_width)\n",
    "                                 \n",
    "        self.head = nn.Sequential(self.get_yang(16*scale_width, 32*scale_width),\n",
    "                                  self.get_yang(32*scale_width, 32*scale_width, last_relu=True))\n",
    "        \n",
    "        params_count(self, 'IMPALA ResNet')\n",
    "\n",
    "    def get_yin(self, in_hiddens, hiddens, out_hiddens):\n",
    "        blocks = nn.Sequential(DQN_Conv(1, hiddens, 3, 1, 1, max_pool=True, act=self.act, norm=self.norm, init=self.init),\n",
    "                               Residual_Block(hiddens, hiddens, norm=self.norm, act=self.act, init=self.init),\n",
    "                               #DQN_Conv(hiddens, out_hiddens, 3, 1, 1, max_pool=True, act=self.act, norm=self.norm, init=self.init),\n",
    "                               #Residual_Block(out_hiddens, out_hiddens, norm=self.norm, act=self.act, init=self.init),\n",
    "                               #Residual_Block(out_hiddens, out_hiddens, norm=self.norm, act=self.act, init=self.init)\n",
    "                              )\n",
    "        return blocks          \n",
    "        \n",
    "    def get_yang(self, in_hiddens, out_hiddens, last_relu=False):\n",
    "        \n",
    "        blocks = nn.Sequential(DQN_Conv(in_hiddens, out_hiddens, 3, 1, 1, max_pool=True, act=self.act, norm=self.norm, init=self.init),\n",
    "                               Residual_Block(out_hiddens, out_hiddens, norm=self.norm, act=self.act, init=self.init),\n",
    "                               Residual_Block(out_hiddens, out_hiddens, norm=self.norm, act=self.act, init=self.init, out_act=self.act if last_relu else nn.Identity())\n",
    "                              )\n",
    "        \n",
    "        return blocks\n",
    "    \n",
    "    def forward(self, X):\n",
    "\n",
    "        y = self.yin(X[:,-3:].mean(-3)[:,None])\n",
    "        x = self.yang(X)\n",
    "        \n",
    "        X = x*(1-y) + x + y\n",
    "        \n",
    "        return self.head(X)\n",
    "\n",
    "model = IMPALA_Resnet(scale_width=4)\n",
    "x=torch.randn(32,12,96,72)\n",
    "model2 = IMPALA_YY(scale_width=4)\n",
    "\n",
    "model(x).shape, model2(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dcc521d-7bac-44e8-9584-ce0bab652aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.1788,  0.1215, -0.1596,  0.0556,  0.0823, -0.0129, -0.1189,  0.1854,\n",
       "          -0.0022, -0.1650],\n",
       "         [-0.1079, -0.0155,  0.0935,  0.0209,  0.0326, -0.1374, -0.1405,  0.0014,\n",
       "           0.1486,  0.0473],\n",
       "         [-0.1218, -0.0415, -0.1404, -0.0332, -0.0325,  0.0417,  0.1003, -0.1978,\n",
       "           0.1183, -0.2110],\n",
       "         [ 0.1376,  0.0622,  0.0658,  0.1490, -0.1540, -0.0291,  0.1021,  0.0194,\n",
       "          -0.0155, -0.1166],\n",
       "         [ 0.1413,  0.0467,  0.0852, -0.0416, -0.0986, -0.0094,  0.0798, -0.0597,\n",
       "          -0.0080,  0.0361],\n",
       "         [-0.0403, -0.0299, -0.0763, -0.1011, -0.1358, -0.0595, -0.0660,  0.0495,\n",
       "           0.0058, -0.1400],\n",
       "         [ 0.1676, -0.0036,  0.1435, -0.1102, -0.0544,  0.0415, -0.0507, -0.1388,\n",
       "          -0.0399, -0.1282],\n",
       "         [-0.0417,  0.0976,  0.1985, -0.0430, -0.1056, -0.2105, -0.1068,  0.0640,\n",
       "           0.1031,  0.0113],\n",
       "         [-0.0810,  0.0300, -0.0838,  0.0648, -0.0344, -0.0191, -0.0008, -0.0291,\n",
       "          -0.0730,  0.0970],\n",
       "         [ 0.0181,  0.0973,  0.1791, -0.0737, -0.1388,  0.1066,  0.1464, -0.1301,\n",
       "          -0.0104, -0.2240],\n",
       "         [-0.1654,  0.0334,  0.0374, -0.0277, -0.0449,  0.0844, -0.0483, -0.1407,\n",
       "          -0.0683, -0.0313],\n",
       "         [ 0.1286, -0.1180,  0.0847, -0.1490, -0.1764, -0.1200,  0.1537,  0.0773,\n",
       "           0.1216,  0.0297],\n",
       "         [ 0.1321, -0.0624, -0.0828,  0.0215, -0.1387, -0.1543, -0.0796, -0.0187,\n",
       "           0.1392, -0.1064],\n",
       "         [-0.0327,  0.0235, -0.1350, -0.0757,  0.0594, -0.0579,  0.0890,  0.0967,\n",
       "           0.0695,  0.0077],\n",
       "         [ 0.0782, -0.0673,  0.0460, -0.0537,  0.0489,  0.1480, -0.0087, -0.0147,\n",
       "           0.0296, -0.1583],\n",
       "         [ 0.0593,  0.0761,  0.1255,  0.0146, -0.0622, -0.1359, -0.0037, -0.0036,\n",
       "           0.0385, -0.2118],\n",
       "         [ 0.1015, -0.1332, -0.0893, -0.1773,  0.1496, -0.1724,  0.0969,  0.0242,\n",
       "          -0.0006,  0.0432],\n",
       "         [-0.0394,  0.0802,  0.1564, -0.1618,  0.0214, -0.0073, -0.0271,  0.0378,\n",
       "           0.1012, -0.1675],\n",
       "         [ 0.0091,  0.1582,  0.1253, -0.0336, -0.1311,  0.0233, -0.0910,  0.1242,\n",
       "          -0.1045, -0.0490],\n",
       "         [-0.0296, -0.0042,  0.1874,  0.0485,  0.0873,  0.0968,  0.1189, -0.0648,\n",
       "          -0.0157,  0.0516],\n",
       "         [-0.0732,  0.0376,  0.0085, -0.1065,  0.0566, -0.0154,  0.0351,  0.1108,\n",
       "           0.1028,  0.1250],\n",
       "         [ 0.0430, -0.1425, -0.1306, -0.1279, -0.1485, -0.0603, -0.1484, -0.1523,\n",
       "          -0.0766, -0.2103],\n",
       "         [-0.1119,  0.0814,  0.1195, -0.0686, -0.1048,  0.1092, -0.0436, -0.0615,\n",
       "           0.0696, -0.2240],\n",
       "         [-0.0229,  0.1712,  0.0652,  0.0895, -0.0668,  0.0070,  0.0054, -0.0098,\n",
       "           0.0127,  0.0470],\n",
       "         [-0.0798, -0.0411, -0.0841, -0.1794, -0.0332, -0.1960,  0.0617,  0.0381,\n",
       "          -0.0976,  0.0966],\n",
       "         [-0.1505, -0.1166, -0.0273, -0.1724, -0.1253, -0.0856,  0.1394,  0.1173,\n",
       "           0.1279, -0.1099],\n",
       "         [-0.0391,  0.0680,  0.1183, -0.0349,  0.0495, -0.0640, -0.0647,  0.1476,\n",
       "          -0.0502, -0.0964],\n",
       "         [-0.0948, -0.1527,  0.0353, -0.0719,  0.0248,  0.0450, -0.1974,  0.0572,\n",
       "          -0.0696, -0.1601],\n",
       "         [ 0.0653,  0.0771, -0.0408, -0.1055, -0.1724, -0.1105, -0.2001,  0.0089,\n",
       "           0.0877, -0.1922],\n",
       "         [ 0.1398,  0.0609, -0.2065, -0.1483,  0.0707, -0.0817, -0.0667, -0.0828,\n",
       "           0.1140, -0.1365],\n",
       "         [ 0.1440, -0.0162,  0.0178,  0.0830, -0.0798, -0.0522, -0.0568,  0.1360,\n",
       "          -0.1322,  0.0088],\n",
       "         [-0.0752,  0.1041,  0.0040,  0.0281,  0.1395,  0.0087,  0.1325, -0.0534,\n",
       "          -0.0239,  0.0520]], device='cuda:0', requires_grad=True))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from nosaveddata import *\n",
    "\n",
    "seed_np_torch(42)\n",
    "\n",
    "def network_ema(target_network, new_network, alpha=0.5):\n",
    "    for (param_name, param_target), param_new  in zip(target_network.cuda().named_parameters(), new_network.parameters()):\n",
    "        if 'ln' in param_name: #layer norm\n",
    "            param_target.data = param_new.data.clone()\n",
    "        else:\n",
    "            param_target.data = alpha * param_target.data + (1 - alpha) * param_new.data.clone()\n",
    "\n",
    "\n",
    "class Modeld(nsd_Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(10,32)\n",
    "        self.ln = nn.LayerNorm(32)\n",
    "\n",
    "    def forward(self,X):\n",
    "        return self.ln(self.linear(X))\n",
    "\n",
    "m = Modeld().cuda()\n",
    "m_rand= Modeld().cuda()\n",
    "\n",
    "\n",
    "optim=torch.optim.AdamW(m.parameters(), lr=1e-4)\n",
    "\n",
    "for i in range(4000):\n",
    "    x=torch.randn(1,10).cuda()\n",
    "    \n",
    "    loss = m(x).sum()\n",
    "    loss.backward()\n",
    "    \n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "\n",
    "network_ema(m,m_rand)\n",
    "\n",
    "m.ln.weight, m.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3912798-5ac5-43f3-b591-98c21b5f71e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\diffusers\\utils\\outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nosaveddata import *\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "model = nn.Linear(10,2).cuda()\n",
    "model.apply(init_xavier)\n",
    "model2 = nn.Linear(10,2).cuda()\n",
    "network_ema(model, model2, 0)\n",
    "model.apply(init_xavier)\n",
    "\n",
    "model.weight.data==model2.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94662c-07ea-4abb-b390-a28cf08d5a81",
   "metadata": {},
   "source": [
    "<h1>Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b3a89a6-7f64-4075-8138-50b0e8229dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Augusto/Python/PyTorch/RL/mc_data/4/2023_01_09_14_48_09_100636/7,0,0,0,0,0,0,0,0,0,0,0,0,3,0,.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     12\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Augusto/Python/PyTorch/RL/mc_data/4/2023_01_09_14_48_09_100636/7,0,0,0,0,0,0,0,0,0,0,0,0,3,0,.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     16\u001b[0m tfms \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     17\u001b[0m                            transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m72\u001b[39m)),\n\u001b[0;32m     18\u001b[0m                            transforms\u001b[38;5;241m.\u001b[39mToTensor()\n\u001b[0;32m     19\u001b[0m                         ])\n\u001b[1;32m---> 21\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(path)\n\u001b[0;32m     22\u001b[0m imgs\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python_\\Lib\\site-packages\\PIL\\Image.py:3243\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3240\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3243\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3244\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Augusto/Python/PyTorch/RL/mc_data/4/2023_01_09_14_48_09_100636/7,0,0,0,0,0,0,0,0,0,0,0,0,3,0,.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os, glob\n",
    "from nosaveddata import *\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "paths = glob.glob('C:/Users/Augusto/Python/PyTorch/RL/mc_data/4/2023_01_09_14_48_09_100636/*.jpg')\n",
    "path = 'C:/Users/Augusto/Python/PyTorch/RL/mc_data/4/2023_01_09_14_48_09_100636/7,0,0,0,0,0,0,0,0,0,0,0,0,3,0,.jpg'\n",
    "\n",
    "\n",
    "\n",
    "tfms = transforms.Compose([\n",
    "                           transforms.Resize((96, 72)),\n",
    "                           transforms.ToTensor()\n",
    "                        ])\n",
    "\n",
    "img = Image.open(path)\n",
    "imgs=[]\n",
    "for p in paths:\n",
    "    imgs.append(tfms(Image.open(p)))\n",
    "imgs=torch.stack(imgs)\n",
    "\n",
    "print(imgs.shape)\n",
    "\n",
    "\n",
    "\n",
    "imgs, augments_applied = preprocess_iwm_no_solarize(imgs)\n",
    "    \n",
    "\n",
    "\n",
    "#plt.imshow(img_tfms)\n",
    "plot_imgs(imgs.permute(0,2,3,1))\n",
    "augments_applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a6f04e-3fe2-4c94-8984-2e74348e007b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 12, 96, 72])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nosaveddata import *\n",
    "\n",
    "\n",
    "\n",
    "def gray_scale_stacked(X, p=0.2, stacks=4):\n",
    "    # Input: Tensor T e (B,C,T,D)\n",
    "    \n",
    "    probs = get_img_preprocessing_prob(X.shape[0], p, X.device)\n",
    "    stacked_probs = probs.repeat_interleave(stacks,0)\n",
    "    X = X.view(-1,X.shape[1]//stacks,*X.shape[-2:])\n",
    "    \n",
    "    gray_img = X.mean(1,keepdim=True).expand(-1,3,-1,-1)\n",
    "    \n",
    "    X = (1-stacked_probs)*X + stacked_probs*gray_img\n",
    "    \n",
    "    return X.view(X.shape[0]//stacks, -1, *X.shape[-2:]), probs.squeeze()\n",
    "\n",
    "def gaussian_blur(X, p=0.2, stacks=4, sigma_min=0.1, sigma_max=2):\n",
    "    # Input: Tensor T e (B,C,T,D)\n",
    "    \n",
    "    probs = get_img_preprocessing_prob(X.shape[0], p, X.device)\n",
    "    tfms = transforms.GaussianBlur(3, (sigma_min, sigma_max))\n",
    "    \n",
    "    blurred = tfms(X)\n",
    "    X = (1-probs)*X + probs*blurred\n",
    "    \n",
    "    return X, probs.squeeze()\n",
    "\n",
    "def solarization_stacked(X, p=0.2, stacks=4):\n",
    "    # Input: Tensor T e (B,C,T,D)\n",
    "\n",
    "    probs = get_img_preprocessing_prob(X.shape[0], p, X.device)\n",
    "    stacked_probs = probs.repeat_interleave(stacks,0)\n",
    "    \n",
    "    X = X.view(-1,X.shape[1]//stacks,*X.shape[-2:])\n",
    "    \n",
    "    tfms = transforms.RandomSolarize(0,p=1) # This prob is applied over all the batch or no image at all\n",
    "    \n",
    "    solarized = tfms(X)\n",
    "    X = (1-stacked_probs)*X + stacked_probs*solarized\n",
    "    \n",
    "    return X.view(X.shape[0]//stacks, -1, *X.shape[-2:]), probs.squeeze()\n",
    "\n",
    "\n",
    "def preprocess_iwm_stacked(imgs, p=0.2, stacks=4):\n",
    "    # Applies the same preprocessing for all images in the sequence, but separated by each beach\n",
    "    augments_applied=[]\n",
    "    \n",
    "    imgs, augmented = gray_scale_stacked(imgs, p, stacks)\n",
    "    augments_applied.append(augmented)\n",
    "    \n",
    "    imgs, augmented = gaussian_blur_stacked(imgs, p, stacks)\n",
    "    augments_applied.append(augmented)\n",
    "    \n",
    "    imgs, augmented = solarization_stacked(imgs, p, stacks)\n",
    "    augments_applied.append(augmented)\n",
    "    \n",
    "    augments_applied = torch.stack(augments_applied,1)\n",
    "    return imgs, augments_applied\n",
    "\n",
    "preprocess_iwm_stacked(torch.randn(32,12,96,72, device='cuda'))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880deeee-5d84-47ef-9775-583dffaba410",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(imgs[-1].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c2cb75-c68e-4775-aa5f-0a5afcec9a9a",
   "metadata": {},
   "source": [
    "<h1>DiT</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "892bf794-e949-4766-a710-0b7002597581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Transformer Parameters: 31.91M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 32, 32])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nosaveddata import *\n",
    "\n",
    "unet = UNet_DiT_S_4(in_channels=4).cuda()\n",
    "x=torch.randn(32,4,32,32).cuda()\n",
    "c=torch.randn(32,384).cuda()\n",
    "t=torch.randint(0,1000,(32,)).cuda()\n",
    "unet(x,t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea6bc6f-523d-4dfa-8ae1-8412cd2d0b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiT Transformer Parameters: 2.38M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 108, 128])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nosaveddata import *\n",
    "\n",
    "\n",
    "model = DiT_Transformer(128, 8, 8, 108).cuda()\n",
    "\n",
    "X = torch.randn(16,108,128).cuda()\n",
    "c = torch.randn(16,128).cuda()\n",
    "\n",
    "model(X,c).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dcafb6-0a86-4b23-a858-ffd84d0d0aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiT_Transformer(512, 8, 8, 128).cuda()\n",
    "\n",
    "X = torch.randn(16,128,512).cuda()\n",
    "c = torch.randn(16,512).cuda()\n",
    "\n",
    "model(X,c).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a7bc2-2f1d-4bd2-a116-59fe67d4e0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34211d-6121-49b9-8e8e-ac989892c917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
